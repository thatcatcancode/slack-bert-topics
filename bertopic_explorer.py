# -*- coding: utf-8 -*-
"""bertopic_explorer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WKZ8Qx156QjEKDp3EqJqtaMXZQDMloxQ

# BERTopic Exploratory Notebook

This notebook walks through loading a CSV, preprocessing text, training a BERTopic model, and visualizing topics. Adjust paths and parameters as needed.
"""

!pip install pandas bertopic umap-learn hdbscan nltk

import os
os.makedirs('output', exist_ok=True)
import pandas as pd
import nltk
from bertopic import BERTopic

# Download NLTK data
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

# Load your data
# Place your CSV (with a 'text' column) in the same directory as this notebook

df = pd.read_csv('input.csv')
df.head()



# Preprocessing
def clean(text):
    import re
    text = re.sub(r'https?://\S+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    return text.lower()

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

STOP = set(stopwords.words('english'))

print(f'Stopwords: {STOP}')

def tokenize(text):
    return [w for w in word_tokenize(clean(text)) if w not in STOP and len(w) > 2]

docs = df['text'].dropna().tolist()
tokenized = [tokenize(doc) for doc in docs]

# Train BERTopic model
model = BERTopic(nr_topics=20)
topics, probs = model.fit_transform(docs)
print(f'Trained with {len(set(topics))} topics')

# Assign topics back to DataFrame
# Create a new DataFrame with the 'text' column and corresponding topics
topics_df = pd.DataFrame({'text': docs, 'topic': topics})

# Instead of merging, directly assign the 'topic' column to the original df
# This ensures the 'topic' column is added correctly to the df DataFrame.
df['topic'] = topics_df['topic']

# Save results
export_path = 'output/topics.csv'
df[['text','topic']].to_csv(export_path, index=False)
print(f'Topic assignments saved to {export_path}')

# Explore topics information
model.get_topic_info()

# Visualize topics
fig = model.visualize_topics()
fig.write_html('output/bertopic_visualization.html')
fig.show()
print('Visualization saved to output/bertopic_visualization.html')

"""## Next steps
- Tweak `nr_topics` to change the number of discovered topics
- Use `model.get_topic(topic_id)` to view the keywords for a specific topic
- Integrate this notebook into a pipeline or wrap in a web app as needed
"""

# Specify the topic ID you want to explore
topic_id = 5  # Replace with the desired topic ID

# Get the keywords for the specified topic
topic_keywords = model.get_topic(topic_id)

# Print the topic keywords
print(f"Keywords for topic {topic_id}:")
for keyword, probability in topic_keywords:
    print(f"- {keyword}: {probability:.4f}")